# CSNN - Convolutional Spiking Neural Network

## Overview

This project implements a Convolutional Spiking Neural Network trained on the `ST-MNIST` dataset, using the `snntorch` and `tonic` libraries.

It follows the [tutorials](https://snntorch.readthedocs.io/en/latest/index.html) present in the documentation of the `snntorch` library, making use of the concepts of Neuromorphic Computing and Spiking Neural Networks.

The accuracy obtained is **87%**, which matches the results in the [official paper](https://arxiv.org/abs/2005.04319) presenting the `ST-MNIST` dataset.

## Spiking Neural Networks (SNNs)

Spiking Neural Networks are a type of artificial neural network that more closely mimic biological neural networks. Unlike traditional artificial neurons that process information as continuous values, SNNs transmit information through discrete spikes. This temporal aspect allows SNNs to process data more efficiently, especially for tasks involving time-series data. They are part of the general domain of Neuromorphic Computing.

Neuromorphic Computing is a computational paradigm that aims to emulate the structure and function of the human brain. It leverages specialized hardware and algorithms to efficiently process sensory data in real-time, making it suitable for applications in robotics, autonomous systems, and sensory data processing.

This proves to be more energy efficient, requiring much less energy than the state-of-the-art for training, while also having an increase in performance, due to the architecture of the specialised hardware.

## ST-MNIST Dataset

The ST-MNIST dataset extends the original MNIST dataset by incorporating time as an additional dimension. Each digit is represented as a series of spikes generated by a simulated event-based camera when a person writes a digit. This dataset contains a total of 6,953 samples, with 5,562 used for training and 1,391 for testing (having a split of 80% to 20% regarding the train and test data). 

### Usage

After setting up the project, the following steps are needed to use the `ST-MNIST` dataset:

1. Retrieve the ST-MNIST Dataset: Download the dataset and place the archive inside the STMNIST folder in the root directory of the project.
2. Transform the Dataset: Convert the event data into a matrix of frames using a defined transformation.
3. Create DataLoaders: Set up DataLoaders for training and testing, allowing efficient batch processing.

## Model Architecture

The model architecture is the same as in the papers below:

- Convolutional Layers: Two convolutional layers to extract spatial features from the input frames.
- Leaky Integrate-and-Fire Neurons: Non-linear activation through spiking neurons to emulate biological behavior.
- Pooling Layers: Max pooling to reduce dimensionality.
- Fully Connected Layer: A final layer for classification into digit classes.

## Results

The model was trained on 80% of the dataset, while being tested on the remaining 20%, keeping a standard approach to the split. A validation set was not included in this process due to the small amount of samples available.

The performance obtained was an accuracy of **87%**, matching the results in the [official paper](https://arxiv.org/abs/2005.04319) presenting the `ST-MNIST` dataset.

## References

- https://snntorch.readthedocs.io/en/latest/index.html
- https://ieeexplore.ieee.org/abstract/document/10242251
- https://arxiv.org/abs/2005.04319
